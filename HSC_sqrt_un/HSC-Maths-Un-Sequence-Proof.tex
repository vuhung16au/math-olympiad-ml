\documentclass[12pt,a4paper]{article}

% Load style packages
\usepackage{styles/dl101-base}
\usepackage{styles/dl101-fonts}
\usepackage{styles/dl101-colors}
% Note: dl101-boxes, dl101-theorems, and dl101-header-footer use chapter commands
% which don't work with article class. We skip them and use custom styling instead.
\usepackage[most]{tcolorbox}
\usepackage{fancyhdr}
\usepackage{geometry}

\geometry{margin=1in}

% Theorem environments - adjusted for article class (section numbering instead of chapter)
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]

% Override header and footer for this document
\fancyhf{}
\rhead{\sffamily\small\textsc{HSC Maths Extension}}
\lhead{\sffamily\small\textsc{Sequence Convergence Proof}}
\cfoot{\sffamily\scriptsize\thepage}
\renewcommand{\headrulewidth}{0.3pt}

% Title
\title{Convergence of the Sequence $u_n = \sqrt{2 + u_{n-1}}$}
\author{Prepared by Vu Hung Nguyen}
\date{Nov 2025}

\begin{document}

\maketitle

\section{Introduction}

This document presents a problem found in \textbf{HSC Mathematics Extension} course, Australian Curriculum, Year 12. 
The problem involves analyzing the convergence of a recursively defined sequence using fundamental theorems 
from calculus and real analysis. 
This topic is essential for students studying advanced sequences and series, 
as it demonstrates the powerful application of the Monotone Convergence Theorem.

We will explore how sequences defined by recurrence relations behave, 
and learn to prove their convergence rigorously. 
The techniques used here are fundamental tools that you will encounter throughout your mathematical studies.

\section{Problem Statement}

Consider the sequence $(u_n)$ defined recursively by:
\begin{equation}
u_n = \sqrt{2 + u_{n-1}}, \quad n \geq 1
\end{equation}
with an initial value $u_0 > 0$.


\textbf{Question:} Does this sequence converge? If so, what is its limit, and how can we prove this convergence?

This problem challenges us to:
\begin{enumerate}[label=\roman*)]
    \item Determine the potential limit (if it exists)
    \item Find the closed-form solution for $u_n$
    \item Prove that the sequence actually converges to this limit
    \item Understand the behavior of the sequence for different starting values
\end{enumerate}

Flip to the next page for the solution.

\newpage

\section{Solution}

To discuss the convergence of the sequence $u_n = \sqrt{2 + u_{n-1}}$ with $u_0 > 0$, we will use the \textbf{Monotone Convergence Theorem}, which states that if a sequence is both monotonic (either increasing or decreasing) and bounded, it must converge.

\begin{tcolorbox}[title=Monotone Convergence Theorem, colback=softivory, colframe=bookpurple, coltitle=white, fonttitle=\bfseries, boxrule=1.5pt, arc=4pt]
If a sequence $(a_n)$ is monotonic (either increasing or decreasing) and bounded, then $(a_n)$ converges.
\end{tcolorbox}

\textbf{Main Result:} The sequence $(u_n)$ \textbf{converges to 2} for any initial value $u_0 > 0$.

\subsection{Finding the Potential Limit}

First, let's assume the sequence converges to a limit $L$. If $u_n \to L$ as $n \to \infty$, then $u_{n-1} \to L$ as well. We can find the value of $L$ by substituting it into the recurrence relation:

\[
L = \sqrt{2 + L}
\]

To solve for $L$, we square both sides (noting that $L$ must be non-negative, as $u_n$ is the result of a principal square root for all $n \ge 1$):

\begin{align*}
L^2 &= 2 + L\\
L^2 - L - 2 &= 0\\
(L - 2)(L + 1) &= 0
\end{align*}

This gives two possible limits: $L = 2$ or $L = -1$.

Since $u_0 > 0$, we have $u_1 = \sqrt{2 + u_0} > 0$. By induction, every term $u_n$ must be positive. Therefore, the limit $L$ must be non-negative.

\textbf{Conclusion:} The only possible limit for the sequence is $L = 2$.

\subsection{Proving Convergence (Monotonicity and Boundedness)}

Now we must prove that the sequence \textit{does} converge. We analyze the behavior of the sequence based on the starting value $u_0$.

To determine if the sequence is increasing or decreasing, we examine when $u_n > u_{n-1}$:

\begin{align*}
\sqrt{2 + u_{n-1}} &> u_{n-1}\\
2 + u_{n-1} &> u_{n-1}^2 \quad \text{(since } u_{n-1} > 0\text{)}\\
0 &> u_{n-1}^2 - u_{n-1} - 2\\
0 &> (u_{n-1} - 2)(u_{n-1} + 1)
\end{align*}

Since $u_{n-1} > 0$, the term $(u_{n-1} + 1)$ is always positive. The inequality simplifies to:

\[
0 > u_{n-1} - 2
\]

which means $u_{n-1} < 2$.

This tells us:
\begin{itemize}
    \item If $u_{n-1} < 2$, then $u_n > u_{n-1}$ (the sequence is \textbf{increasing}).
    \item If $u_{n-1} > 2$, then $u_n < u_{n-1}$ (the sequence is \textbf{decreasing}).
    \item If $u_{n-1} = 2$, then $u_n = 2$ (the sequence is \textbf{constant}).
\end{itemize}

We can now analyze the convergence by cases.

\subsubsection{Case 1: $u_0 = 2$}

If $u_0 = 2$, then $u_1 = \sqrt{2 + 2} = 2$. By induction, $u_n = 2$ for all $n$.

\textbf{Conclusion:} The sequence is constant and \textbf{converges to 2}.

\subsubsection{Case 2: $0 < u_0 < 2$}

\begin{enumerate}[label=\alph*)]
    \item \textbf{Monotonicity:} We know that if $u_{n-1} < 2$, the sequence increases. Let's prove by induction that $u_n$ \textit{stays} below 2.
    \begin{itemize}
        \item \textbf{Base Case:} $u_0 < 2$ (given).
        \item \textbf{Inductive Step:} Assume $u_k < 2$. Then 
        \[
        u_{k+1} = \sqrt{2 + u_k} < \sqrt{2 + 2} = \sqrt{4} = 2.
        \]
        \item Thus, $u_n < 2$ for all $n$.
        \item Because $u_n < 2$ for all $n$, it follows from our earlier analysis that $u_{n+1} > u_n$ for all $n$. The sequence is \textbf{strictly increasing}.
    \end{itemize}
    
    \item \textbf{Boundedness:} We just proved by induction that $u_n < 2$ for all $n$. The sequence is \textbf{bounded above by 2}.
\end{enumerate}

\textbf{Conclusion (Case 2):} The sequence is increasing and bounded above. By the Monotone Convergence Theorem, it converges. As shown in Step 1, the only possible limit is 2.

\subsubsection{Case 3: $u_0 > 2$}

\begin{enumerate}[label=\alph*)]
    \item \textbf{Monotonicity:} We know that if $u_{n-1} > 2$, the sequence decreases. Let's prove by induction that $u_n$ \textit{stays} above 2.
    \begin{itemize}
        \item \textbf{Base Case:} $u_0 > 2$ (given).
        \item \textbf{Inductive Step:} Assume $u_k > 2$. Then 
        \[
        u_{k+1} = \sqrt{2 + u_k} > \sqrt{2 + 2} = \sqrt{4} = 2.
        \]
        \item Thus, $u_n > 2$ for all $n$.
        \item Because $u_n > 2$ for all $n$, it follows from our earlier analysis that $u_{n+1} < u_n$ for all $n$. The sequence is \textbf{strictly decreasing}.
    \end{itemize}
    
    \item \textbf{Boundedness:} We just proved by induction that $u_n > 2$ for all $n$. The sequence is \textbf{bounded below by 2}.
\end{enumerate}

\textbf{Conclusion (Case 3):} The sequence is decreasing and bounded below. By the Monotone Convergence Theorem, it converges. As shown in Step 1, the only possible limit is 2.

\subsection{Summary}

In all possible cases for $u_0 > 0$, the sequence $(u_n)$ is monotonic and bounded, and therefore \textbf{it always converges to the limit 2}.

This result demonstrates the power of the Monotone Convergence Theorem: by simply showing that a sequence is monotonic and bounded, we can guarantee its convergence without needing to compute the limit directly from the recurrence relation.

\section{Finding Closed Forms}

While the Monotone Convergence Theorem proves convergence, we can also find explicit closed-form expressions for $u_n$ by treating the recurrence relation as a difference equation. This approach uses trigonometric and hyperbolic substitutions to derive exact formulas.

\subsection{Difference Equation Approach: Closed-Form Solutions}

The recurrence relation $u_n = \sqrt{2 + u_{n-1}}$ is a \textbf{non-linear first-order difference equation}. We can find closed-form solutions using clever substitutions based on trigonometric and hyperbolic identities. The form $\sqrt{2 + ...}$ suggests using the half-angle identities.

\subsubsection{Case 1: $0 < u_0 \le 2$}

We use the substitution \textbf{$u_n = 2\cos(\theta_n)$}. The half-angle identity for cosine is $\cos(x/2) = \sqrt{\frac{1 + \cos(x)}{2}}$, which can be rewritten as $2\cos(x/2) = \sqrt{2 + 2\cos(x)}$.

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Substitute:}
    \begin{align*}
    u_n &= \sqrt{2 + u_{n-1}}\\
    2\cos(\theta_n) &= \sqrt{2 + 2\cos(\theta_{n-1})}
    \end{align*}
    
    \item \textbf{Apply Identity:}
    \begin{align*}
    2\cos(\theta_n) &= \sqrt{2(1 + \cos(\theta_{n-1}))}\\
    2\cos(\theta_n) &= \sqrt{2(2\cos^2(\theta_{n-1}/2))}\\
    2\cos(\theta_n) &= \sqrt{4\cos^2(\theta_{n-1}/2)}\\
    2\cos(\theta_n) &= 2|\cos(\theta_{n-1}/2)|
    \end{align*}
    
    \item \textbf{Solve for $\theta_n$:}
    Since $0 < u_0 \le 2$, we can set $u_0 = 2\cos(\theta_0)$ for some $\theta_0 \in [0, \pi/2)$. In this interval, $\cos$ is non-negative, so we can drop the absolute value.
    
    This gives $\theta_n = \theta_{n-1}/2$, which is a simple geometric progression. The solution is:
    \[
    \theta_n = \frac{\theta_0}{2^n}
    \]
    
    \item \textbf{Find the Closed-Form Solution:}
    From $u_0 = 2\cos(\theta_0)$, we have $\theta_0 = \arccos(u_0/2)$.
    
    Substituting back, the closed-form solution for $u_n$ is:
    \[
    u_n = 2\cos\left(\frac{\arccos(u_0/2)}{2^n}\right)
    \]
    
    \item \textbf{Discuss Convergence:}
    As $n \to \infty$, the argument of cosine goes to zero:
    \[
    \lim_{n \to \infty} \left(\frac{\arccos(u_0/2)}{2^n}\right) = 0
    \]
    Therefore, the limit of $u_n$ is:
    \[
    \lim_{n \to \infty} u_n = 2\cos(0) = 2 \cdot 1 = 2
    \]
\end{enumerate}

\subsubsection{Case 2: $u_0 > 2$}

The substitution $u_n = 2\cos(\theta_n)$ fails because $u_0/2 > 1$, which is outside the domain of $\arccos$. We use the hyperbolic cosine equivalent: \textbf{$u_n = 2\cosh(\theta_n)$}. The identity is $2\cosh(x/2) = \sqrt{2 + 2\cosh(x)}$.

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Substitute:}
    \begin{align*}
    u_n &= \sqrt{2 + u_{n-1}}\\
    2\cosh(\theta_n) &= \sqrt{2 + 2\cosh(\theta_{n-1})}
    \end{align*}
    
    \item \textbf{Apply Identity:}
    \begin{align*}
    2\cosh(\theta_n) &= \sqrt{2(1 + \cosh(\theta_{n-1}))}\\
    2\cosh(\theta_n) &= \sqrt{2(2\cosh^2(\theta_{n-1}/2))}\\
    2\cosh(\theta_n) &= 2\cosh(\theta_{n-1}/2) \quad \text{(since $\cosh(x) > 0$ for all $x$)}
    \end{align*}
    
    \item \textbf{Solve for $\theta_n$:}
    This again gives $\theta_n = \theta_{n-1}/2$, so:
    \[
    \theta_n = \frac{\theta_0}{2^n}
    \]
    
    \item \textbf{Find the Closed-Form Solution:}
    From $u_0 = 2\cosh(\theta_0)$, we have $\theta_0 = \text{arccosh}(u_0/2)$.
    
    The closed-form solution is:
    \[
    u_n = 2\cosh\left(\frac{\text{arccosh}(u_0/2)}{2^n}\right)
    \]
    
    \item \textbf{Discuss Convergence:}
    As $n \to \infty$, the argument of $\cosh$ goes to zero:
    \[
    \lim_{n \to \infty} u_n = 2\cosh(0) = 2 \cdot 1 = 2
    \]
\end{enumerate}

\textbf{Conclusion (Difference Equation):} Both cases ($u_0 \le 2$ and $u_0 > 2$) lead to the same limit, \textbf{2}, confirming our earlier result from the Monotone Convergence Theorem.

\subsection{Complex Number Approach: Unified Solution}

The two separate cases can be elegantly unified using complex numbers. Since $\cosh(x) = \cos(ix)$ for real $x$, we can express both cases using a single complex formulation.

\subsubsection{Unified Complex Representation}

We use the substitution \textbf{$u_n = 2\cos(\theta_n)$}, where $\theta_n$ is now allowed to be \textbf{complex}.

\begin{enumerate}[label=\arabic*.]
    \item \textbf{Substitute:}
    \begin{align*}
    u_n &= \sqrt{2 + u_{n-1}}\\
    2\cos(\theta_n) &= \sqrt{2 + 2\cos(\theta_{n-1})}
    \end{align*}
    
    \item \textbf{Apply the Half-Angle Identity:}
    Using the identity $2\cos(x/2) = \sqrt{2 + 2\cos(x)}$ (which holds for complex $x$), we obtain:
    \[
    2\cos(\theta_n) = 2\cos(\theta_{n-1}/2)
    \]
    
    This gives us the recurrence relation:
    \[
    \theta_n = \frac{\theta_{n-1}}{2}
    \]
    
    Which has the solution:
    \[
    \theta_n = \frac{\theta_0}{2^n}
    \]
    
    \item \textbf{Determine $\theta_0$ from $u_0$:}
    
    We need to solve $u_0 = 2\cos(\theta_0)$ for $\theta_0$. The inverse function $\arccos$ can be extended to the complex plane.
    
    \begin{itemize}
        \item \textbf{Case 1: $0 < u_0 \le 2$}\\
        Here, $u_0/2 \in (0, 1]$, so we can take $\theta_0 = \arccos(u_0/2)$ where $\arccos$ returns a real value in $[0, \pi/2)$.
        
        \item \textbf{Case 2: $u_0 > 2$}\\
        When $u_0/2 > 1$, we need to use the complex extension of $\arccos$. Using the identity $\cos(i\alpha) = \cosh(\alpha)$ for real $\alpha$, we can write:
        \[
        \theta_0 = i\alpha, \quad \text{where } \alpha = \text{arccosh}(u_0/2)
        \]
        This gives $u_0 = 2\cos(i\alpha) = 2\cosh(\alpha)$, which is consistent with our earlier hyperbolic substitution.
    \end{itemize}
    
    \item \textbf{Unified Closed-Form Solution:}
    
    The closed-form solution can be written as:
    \[
    u_n = 2\cos\left(\frac{\theta_0}{2^n}\right)
    \]
    where $\theta_0$ is determined by:
    \[
    \theta_0 = \begin{cases}
        \arccos(u_0/2) & \text{if } 0 < u_0 \le 2 \text{ (real $\theta_0$)}\\
        i\cdot\text{arccosh}(u_0/2) & \text{if } u_0 > 2 \text{ (purely imaginary $\theta_0$)}
    \end{cases}
    \]
    
    \item \textbf{Complex Exponential Form:}
    
    Using Euler's formula, we can express this more elegantly. Since $\cos(z) = \frac{e^{iz} + e^{-iz}}{2}$ for any complex $z$, we have:
    \[
    u_n = e^{i\theta_n} + e^{-i\theta_n} = e^{i\theta_0/2^n} + e^{-i\theta_0/2^n}
    \]
    where the principal square root ensures we take the real part.
    
    More precisely, since $u_n$ must be real and positive:
    \[
    u_n = \Re\left(e^{i\theta_0/2^n} + e^{-i\theta_0/2^n}\right) = 2\Re\left(\cos\left(\frac{\theta_0}{2^n}\right)\right)
    \]
    
    \item \textbf{Verification of Both Cases:}
    
    \begin{itemize}
        \item \textbf{When $u_0 \le 2$:} $\theta_0$ is real, so $u_n = 2\cos(\theta_0/2^n)$, matching our trigonometric solution.
        
        \item \textbf{When $u_0 > 2$:} $\theta_0 = i\alpha$ where $\alpha = \text{arccosh}(u_0/2)$ is real. Then:
        \[
        u_n = 2\cos\left(\frac{i\alpha}{2^n}\right) = 2\cos\left(i\cdot\frac{\alpha}{2^n}\right) = 2\cosh\left(\frac{\alpha}{2^n}\right)
        \]
        which matches our hyperbolic solution.
    \end{itemize}
    
    \item \textbf{Convergence:}
    
    As $n \to \infty$, we have:
    \[
    \lim_{n \to \infty} \frac{\theta_0}{2^n} = 0
    \]
    regardless of whether $\theta_0$ is real or purely imaginary. Therefore:
    \[
    \lim_{n \to \infty} u_n = 2\cos(0) = 2\cosh(0) = 2
    \]
\end{enumerate}

\subsubsection{Alternative Complex Exponential Derivation}

We can also derive this directly from the recurrence relation using complex exponentials. Starting from:
\[
u_n^2 = 2 + u_{n-1}
\]

If we let $u_n = z_n + \bar{z}_n$ where $z_n$ is complex and $\bar{z}_n$ is its complex conjugate, then $u_n = 2\Re(z_n)$. The recurrence becomes:
\[
(z_n + \bar{z}_n)^2 = 2 + (z_{n-1} + \bar{z}_{n-1})
\]

A particularly elegant choice is $z_n = e^{i\theta_n}$, which gives $u_n = 2\cos(\theta_n)$. Substituting into $u_n^2 = 2 + u_{n-1}$:
\[
4\cos^2(\theta_n) = 2 + 2\cos(\theta_{n-1})
\]

Using the double-angle identity $2\cos^2(x) = 1 + \cos(2x)$:
\[
2(1 + \cos(2\theta_n)) = 2 + 2\cos(\theta_{n-1})
\]

Simplifying gives $\cos(2\theta_n) = \cos(\theta_{n-1})$, which leads to $2\theta_n = \theta_{n-1}$ (choosing the appropriate branch), yielding $\theta_n = \theta_0/2^n$ as before.

\textbf{Conclusion (Complex Approach):} The complex number formulation elegantly unifies both the trigonometric and hyperbolic cases into a single expression $u_n = 2\cos(\theta_0/2^n)$, where $\theta_0$ takes real or purely imaginary values depending on the initial condition. This demonstrates the power of complex analysis in providing unified solutions to problems that initially appear to require separate treatments.

\subsection{Differential Equation Approach: Continuous Analogue}

We can analyze the stability of the system by approximating the discrete difference equation with an autonomous differential equation. The discrete change is $u_n - u_{n-1} = \sqrt{2 + u_{n-1}} - u_{n-1}$.

We approximate this with a continuous function $u(t)$, where the change $u'(t)$ is analogous to $u_n - u_{n-1}$.

The associated differential equation is:
\begin{equation}
\frac{du}{dt} = \sqrt{2 + u} - u
\end{equation}

\subsubsection{Finding Equilibria (Fixed Points)}

The equilibria occur where the system is stable, i.e., $\frac{du}{dt} = 0$.
\begin{align*}
\sqrt{2 + u} - u &= 0\\
\sqrt{2 + u} &= u\\
2 + u &= u^2\\
u^2 - u - 2 &= 0\\
(u - 2)(u + 1) &= 0
\end{align*}

Since $u_0 > 0$ (and all subsequent $u_n > 0$), we are only interested in non-negative equilibria. The only relevant equilibrium point is \textbf{$u = 2$}.

\subsubsection{Analyzing Stability of the Equilibrium}

We check the sign of $\frac{du}{dt}$ on either side of the equilibrium point $u=2$. Let $g(u) = \frac{du}{dt} = \sqrt{2 + u} - u$.

\begin{itemize}
    \item \textbf{Region 1: $0 < u < 2$}\\
    Let's pick a test value, e.g., $u = 1$.
    \[
    g(1) = \sqrt{2 + 1} - 1 = \sqrt{3} - 1 \approx 1.732 - 1 = 0.732 > 0
    \]
    Since $\frac{du}{dt} > 0$, the function $u(t)$ is \textbf{increasing} in this region. The value of $u$ moves \textit{towards} 2.
    
    \item \textbf{Region 2: $u > 2$}\\
    Let's pick a test value, e.g., $u = 7$.
    \[
    g(7) = \sqrt{2 + 7} - 7 = \sqrt{9} - 7 = 3 - 7 = -4 < 0
    \]
    Since $\frac{du}{dt} < 0$, the function $u(t)$ is \textbf{decreasing} in this region. The value of $u$ moves \textit{towards} 2.
\end{itemize}

\subsubsection{Conclusion (Differential Equation)}

We can visualize this on a phase line:

\[
\ldots (0) \xrightarrow{\text{increasing}} [2] \xleftarrow{\text{decreasing}} (\infty) \ldots
\]

Because the system's flow (represented by the arrows) points towards $u=2$ from both sides, $u=2$ is an \textbf{asymptotically stable equilibrium}.

This analysis of the continuous analogue strongly implies that the discrete system (our sequence) will also be attracted to this fixed point. Regardless of the starting value $u_0 > 0$, the sequence will move towards and ultimately \textbf{converge to 2}.

\section{Non-Monotonic Sequence with Noise}

\subsection{Problem Statement}

What happens if we modify the recurrence relation by adding a small "noise" term? Consider the modified sequence:

\begin{equation}
u_n = \sqrt{2 + u_{n-1} + \epsilon_{n-1}}, \quad n \geq 1
\end{equation}

where $(\epsilon_n)$ is a sequence of non-negative numbers. 

\textbf{Question:} Can we choose $(\epsilon_n)$ such that the sequence $(u_n)$ becomes \textbf{non-monotonic} while still converging to 2?

This is an interesting extension that shows how sequences can converge even when they are not monotonic.

\subsection{Solution}

Yes! We can construct such a sequence. The key insight is to use a noise sequence $(\epsilon_n)$ that:
\begin{itemize}
    \item Is large enough initially to "kick" the sequence above 2
    \item Decays to 0 as $n \to \infty$, so the modified sequence still converges to 2
\end{itemize}

\subsubsection{The Epsilon Sequence}

Let's define the noise sequence $(\epsilon_n)$ as a simple decaying function:

\[
\epsilon_n = \frac{1}{n+1}
\]

So, the sequence $(\epsilon_n)$ is:
\begin{itemize}
    \item $\epsilon_0 = 1/1 = 1$
    \item $\epsilon_1 = 1/2 = 0.5$
    \item $\epsilon_2 = 1/3 \approx 0.333$
    \item $\epsilon_3 = 1/4 = 0.25$
    \item $\epsilon_4 = 1/5 = 0.2$
    \item $\ldots$ (continuing indefinitely)
\end{itemize}

This sequence is simple, non-negative, and clearly converges to 0 as $n \to \infty$.

\subsubsection{Analyzing the Modified Sequence}

Now let's trace the sequence $u_n = \sqrt{2 + u_{n-1} + \epsilon_{n-1}}$ using this noise. The key to making $u_n$ non-monotonic is to start it \textit{below} 2, let the noise "kick" it \textit{above} 2, and then watch it oscillate.

Let's pick an initial value of \textbf{$u_0 = 1.5$}.

\begin{enumerate}
    \item \textbf{Calculate $u_1$:}
    \begin{align*}
    u_1 &= \sqrt{2 + u_0 + \epsilon_0}\\
    u_1 &= \sqrt{2 + 1.5 + 1} = \sqrt{4.5}\\
    u_1 &\approx 2.121
    \end{align*}
    The sequence increased: $2.121 > 1.5$
    
    \item \textbf{Calculate $u_2$:}
    \begin{align*}
    u_2 &= \sqrt{2 + u_1 + \epsilon_1}\\
    u_2 &= \sqrt{2 + 2.121 + 0.5} = \sqrt{4.621}\\
    u_2 &\approx 2.149
    \end{align*}
    The sequence increased again: $2.149 > 2.121$
    
    \item \textbf{Calculate $u_3$:}
    \begin{align*}
    u_3 &= \sqrt{2 + u_2 + \epsilon_2}\\
    u_3 &= \sqrt{2 + 2.149 + 0.333} = \sqrt{4.482}\\
    u_3 &\approx 2.117
    \end{align*}
    The sequence \textbf{decreased}: $2.117 < 2.149$
\end{enumerate}

\subsubsection{Conclusion}

The sequence $(u_n)$ is \textbf{non-monotonic} because it went up ($u_2 > u_1$) and then came down ($u_3 < u_2$).

However, the sequence \textbf{still converges to 2}. The "noise" $\epsilon_n = \frac{1}{n+1}$ gets smaller and smaller, so its effect diminishes. The sequence's natural "pull" towards the stable limit of 2 eventually takes over, and $u_n$ will converge to 2.

This example demonstrates an important principle: \textbf{monotonicity is sufficient but not necessary for convergence}. Sequences can converge even when they oscillate, as long as the oscillations become smaller over time.

\section{Final Thoughts}

This problem beautifully illustrates several key concepts in sequence convergence:
\begin{itemize}
    \item The Monotone Convergence Theorem as a powerful tool for proving convergence
    \item How to find potential limits by analyzing the recurrence relation
    \item The importance of considering different cases (initial conditions)
    \item That convergence does not require monotonicity
\end{itemize}

Understanding these ideas will serve you well in more advanced mathematical studies, including calculus, real analysis, and beyond.

\section{Exercises}

The following exercises will help you deepen your understanding of sequence convergence and the techniques we've discussed. Try to solve them using the methods from this document.

\begin{enumerate}
    \item \textbf{Non-Monotonic Sequence with Alternating Noise}\\
    Consider the modified sequence:
    \[
    u_n = \sqrt{2 + u_{n-1} + \epsilon_{n-1}}, \quad n \geq 1
    \]
    where $\epsilon_n = (-1)^n \cdot \frac{1}{n+1}$ for $n \geq 0$ and $u_0 = 1.5$. Show that this sequence converges to 2 despite being non-monotonic.
    
    \textbf{Hint:} The noise alternates in sign. Consider the behavior of $u_n$ when the noise is positive versus negative. Use the fact that $|\epsilon_n| \to 0$ as $n \to \infty$.
    
    \item \textbf{Modified Recurrence: $\sqrt{1 + u_{n-1}}$}\\
    Consider the sequence defined by:
    \[
    u_n = \sqrt{1 + u_{n-1}}, \quad n \geq 1
    \]
    with $u_0 > 0$. Determine whether this sequence converges, and if so, find its limit. Prove your result using the Monotone Convergence Theorem.
    
    \textbf{Hint:} Start by finding the potential fixed point(s) by solving $L = \sqrt{1 + L}$ for $L$. Then analyze monotonicity and boundedness similar to the original problem.
    
    \item \textbf{Cube Root Recurrence: $\sqrt[3]{6 + u_{n-1}}$}\\
    Consider the sequence defined by:
    \[
    u_n = \sqrt[3]{6 + u_{n-1}}, \quad n \geq 1
    \]
    with $u_0 > 0$.
    \begin{enumerate}[label=\roman*)]
        \item Show that the associated differential equation $\frac{du}{dt} = \sqrt[3]{6 + u} - u$ has exactly one fixed point.
        \item Prove that the sequence $(u_n)$ is monotonic (either increasing or decreasing depending on $u_0$).
        \item Find the limit of the sequence and prove convergence.
    \end{enumerate}
    
    \textbf{Hint:} For part (i), solve $\sqrt[3]{6 + u} = u$ to find the fixed point. For part (ii), compare $u_n$ with $u_{n-1}$ by considering the function $f(x) = \sqrt[3]{6 + x} - x$.
    
    \item \textbf{Generalized Recurrence: $\sqrt{a + u_{n-1}}$}\\
    Consider the sequence defined by:
    \[
    u_n = \sqrt{a + u_{n-1}}, \quad n \geq 1
    \]
    where $a > 0$ is a constant and $u_0 > 0$.
    \begin{enumerate}[label=\roman*)]
        \item Find all possible limits of the sequence in terms of $a$.
        \item For which values of $a$ does the sequence converge for any initial value $u_0 > 0$?
        \item Investigate the behavior when $a = 0$. Does the sequence converge? If so, to what?
    \end{enumerate}
    
    \textbf{Hint:} Start by finding fixed points: solve $L = \sqrt{a + L}$. Consider the discriminant of the resulting quadratic equation. For part (iii), think carefully about the domain and what happens when $a = 0$.
    
    \item \textbf{Rate of Convergence}\\
    For the original sequence $u_n = \sqrt{2 + u_{n-1}}$ with $0 < u_0 < 2$, we showed that $u_n \to 2$ as $n \to \infty$. 
    \begin{enumerate}[label=\roman*)]
        \item Show that $2 - u_n = O(1/2^n)$ as $n \to \infty$ (i.e., the error decreases exponentially).
        \item More precisely, using the closed-form solution $u_n = 2\cos(\theta_0/2^n)$, show that:
        \[
        2 - u_n \sim \frac{\theta_0^2}{2^{2n+1}} \quad \text{as } n \to \infty
        \]
        where $\theta_0 = \arccos(u_0/2)$ and $\sim$ means asymptotic equivalence.
    \end{enumerate}
    
    \textbf{Hint:} For part (i), use the fact that $u_n = 2\cos(\theta_0/2^n)$ and consider the Taylor expansion of $\cos(x)$ near $x = 0$. For part (ii), use $\cos(x) = 1 - x^2/2 + O(x^4)$.
\end{enumerate}

\newpage

\section{Solutions to Exercises}

\subsection{Solution to Exercise 1: Non-Monotonic Sequence with Alternating Noise}

We need to show that the sequence $u_n = \sqrt{2 + u_{n-1} + \epsilon_{n-1}}$ with $\epsilon_n = (-1)^n \cdot \frac{1}{n+1}$ and $u_0 = 1.5$ converges to 2, despite being non-monotonic.

\textbf{Step 1: Showing the sequence is non-monotonic}

Let's compute the first few terms:
\begin{align*}
u_0 &= 1.5\\
u_1 &= \sqrt{2 + 1.5 + \epsilon_0} = \sqrt{2 + 1.5 + 1} = \sqrt{4.5} \approx 2.121\\
u_2 &= \sqrt{2 + 2.121 + \epsilon_1} = \sqrt{2 + 2.121 - 0.5} = \sqrt{3.621} \approx 1.903\\
u_3 &= \sqrt{2 + 1.903 + \epsilon_2} = \sqrt{2 + 1.903 + 0.333} = \sqrt{4.236} \approx 2.058
\end{align*}

We see that $u_1 \approx 2.121$, $u_2 \approx 1.903$, and $u_3 \approx 2.058$. So $u_1 > u_2$ (the sequence decreases from $u_1$ to $u_2$) and $u_2 < u_3$ (the sequence increases from $u_2$ to $u_3$), showing the sequence is \textbf{non-monotonic}.

\textbf{Step 2: Showing convergence to 2}

We have $u_n = \sqrt{2 + u_{n-1} + \epsilon_{n-1}}$ where $|\epsilon_n| = \frac{1}{n+1} \to 0$ as $n \to \infty$.

Since $|\epsilon_n| \to 0$, for any $\delta > 0$, there exists $N$ such that $|\epsilon_n| < \delta$ for all $n \geq N$. This means that for large $n$, the modified sequence behaves almost like the original sequence $v_n = \sqrt{2 + v_{n-1}}$, which we know converges to 2.

More rigorously, consider the difference:
\[
|u_n - 2| = \left|\sqrt{2 + u_{n-1} + \epsilon_{n-1}} - 2\right|
\]

Using the fact that $\sqrt{2 + u_{n-1} + \epsilon_{n-1}} = \sqrt{2 + u_{n-1}} \cdot \sqrt{1 + \frac{\epsilon_{n-1}}{2 + u_{n-1}}}$, and since $u_n > 0$ for all $n$, we have:
\[
|u_n - 2| \leq \left|\sqrt{2 + u_{n-1}} - 2\right| + \left|\sqrt{2 + u_{n-1}}\right| \cdot \left|\sqrt{1 + \frac{\epsilon_{n-1}}{2 + u_{n-1}}} - 1\right|
\]

Since $|\epsilon_{n-1}| \to 0$ and $u_{n-1}$ is bounded (the sequence oscillates around 2), the second term goes to 0. The first term represents the error from the unmodified sequence, which also converges to 0.

By the Squeeze Theorem (or using the fact that the "noise" decays to 0), we conclude that $\lim_{n \to \infty} u_n = 2$.

\subsection{Solution to Exercise 2: Modified Recurrence $\sqrt{1 + u_{n-1}}$}

Consider $u_n = \sqrt{1 + u_{n-1}}$ with $u_0 > 0$.

\textbf{Step 1: Finding potential limits}

If the sequence converges to $L$, then:
\[
L = \sqrt{1 + L} \quad \Rightarrow \quad L^2 = 1 + L \quad \Rightarrow \quad L^2 - L - 1 = 0
\]

Using the quadratic formula:
\[
L = \frac{1 \pm \sqrt{1 + 4}}{2} = \frac{1 \pm \sqrt{5}}{2}
\]

Since $u_n > 0$ for all $n$, we must have $L \geq 0$. The negative root $\frac{1 - \sqrt{5}}{2} < 0$ is invalid. Therefore, the only possible limit is:
\[
L = \frac{1 + \sqrt{5}}{2} = \phi
\]
where $\phi$ is the golden ratio (approximately 1.618).

\textbf{Step 2: Proving convergence using Monotone Convergence Theorem}

We analyze monotonicity by comparing $u_n$ and $u_{n-1}$:
\[
u_n > u_{n-1} \quad \Leftrightarrow \quad \sqrt{1 + u_{n-1}} > u_{n-1} \quad \Leftrightarrow \quad 1 + u_{n-1} > u_{n-1}^2
\]

This simplifies to:
\[
u_{n-1}^2 - u_{n-1} - 1 < 0
\]

The roots of $x^2 - x - 1 = 0$ are $\frac{1 \pm \sqrt{5}}{2}$. The quadratic is negative between these roots. Since we only care about positive values:
\[
0 < u_{n-1} < \frac{1 + \sqrt{5}}{2} = \phi
\]

So:
\begin{itemize}
    \item If $u_{n-1} < \phi$, then $u_n > u_{n-1}$ (sequence increases)
    \item If $u_{n-1} > \phi$, then $u_n < u_{n-1}$ (sequence decreases)
    \item If $u_{n-1} = \phi$, then $u_n = \phi$ (sequence is constant)
\end{itemize}

\textbf{Case 1: $0 < u_0 < \phi$}
By induction, $u_n < \phi$ for all $n$ (since $\sqrt{1 + u_{n-1}} < \sqrt{1 + \phi} = \phi$). The sequence is increasing and bounded above by $\phi$, so it converges. The limit must be $\phi$.

\textbf{Case 2: $u_0 > \phi$}
By induction, $u_n > \phi$ for all $n$. The sequence is decreasing and bounded below by $\phi$, so it converges. The limit must be $\phi$.

\textbf{Case 3: $u_0 = \phi$}
Then $u_n = \phi$ for all $n$, so it trivially converges to $\phi$.

\textbf{Conclusion:} The sequence converges to $\phi = \frac{1 + \sqrt{5}}{2}$ for any $u_0 > 0$.

\subsection{Solution to Exercise 3: Cube Root Recurrence $\sqrt[3]{6 + u_{n-1}}$}

Consider $u_n = \sqrt[3]{6 + u_{n-1}}$ with $u_0 > 0$.

\textbf{Part (i): Fixed point of the differential equation}

The associated differential equation is $\frac{du}{dt} = \sqrt[3]{6 + u} - u$. Fixed points occur when:
\[
\sqrt[3]{6 + u} - u = 0 \quad \Rightarrow \quad \sqrt[3]{6 + u} = u \quad \Rightarrow \quad 6 + u = u^3
\]

Rearranging: $u^3 - u - 6 = 0$.

Let $f(u) = u^3 - u - 6$. We have $f(0) = -6 < 0$ and $f(2) = 8 - 2 - 6 = 0$. Actually, $f(2) = 0$, so $u = 2$ is a root. Let's verify: $f(2) = 8 - 2 - 6 = 0$. Yes, $u = 2$ is a fixed point.

To show this is the only positive fixed point, we can factor the cubic: $u^3 - u - 6 = (u - 2)(u^2 + 2u + 3)$. The quadratic $u^2 + 2u + 3$ has discriminant $4 - 12 = -8 < 0$, so it has no real roots. Therefore, $u = 2$ is the only real root, and thus the differential equation has \textbf{exactly one fixed point}.

\textbf{Part (ii): Monotonicity}

We compare $u_n$ and $u_{n-1}$:
\[
u_n \gtreqless u_{n-1} \quad \Leftrightarrow \quad \sqrt[3]{6 + u_{n-1}} \gtreqless u_{n-1} \quad \Leftrightarrow \quad 6 + u_{n-1} \gtreqless u_{n-1}^3
\]

This gives: $u_{n-1}^3 - u_{n-1} - 6 \lesseqgtr 0$.

Since $f(x) = x^3 - x - 6 = (x - 2)(x^2 + 2x + 3)$ and $x^2 + 2x + 3 > 0$ for all real $x$, the sign of $f(x)$ is determined by $(x - 2)$. Therefore:
\begin{itemize}
    \item If $u_{n-1} < 2$, then $f(u_{n-1}) < 0$, so $u_n > u_{n-1}$ (sequence increases)
    \item If $u_{n-1} > 2$, then $f(u_{n-1}) > 0$, so $u_n < u_{n-1}$ (sequence decreases)
    \item If $u_{n-1} = 2$, then $u_n = 2$ (sequence is constant)
\end{itemize}

Therefore, the sequence is \textbf{monotonic} (either strictly increasing if $u_0 < 2$, strictly decreasing if $u_0 > 2$, or constant if $u_0 = 2$).

\textbf{Part (iii): Finding the limit and proving convergence}

By induction:
\begin{itemize}
    \item If $u_0 < 2$, then $u_n < 2$ for all $n$, and the sequence is increasing and bounded above by 2.
    \item If $u_0 > 2$, then $u_n > 2$ for all $n$, and the sequence is decreasing and bounded below by 2.
\end{itemize}

By the Monotone Convergence Theorem, the sequence converges. The limit must satisfy $L = \sqrt[3]{6 + L}$, which gives $L^3 - L - 6 = 0$. Since $L = 2$ is the unique positive root, we have $\lim_{n \to \infty} u_n = 2$.

\subsection{Solution to Exercise 4: Generalized Recurrence $\sqrt{a + u_{n-1}}$}

Consider $u_n = \sqrt{a + u_{n-1}}$ where $a > 0$ is a constant and $u_0 > 0$.

\textbf{Part (i): Finding all possible limits}

If the sequence converges to $L$, then:
\[
L = \sqrt{a + L} \quad \Rightarrow \quad L^2 = a + L \quad \Rightarrow \quad L^2 - L - a = 0
\]

Using the quadratic formula:
\[
L = \frac{1 \pm \sqrt{1 + 4a}}{2}
\]

Since $u_n > 0$ for all $n$, we require $L \geq 0$. The negative root $\frac{1 - \sqrt{1 + 4a}}{2}$ is negative for $a > 0$, so it's invalid. Therefore, the only possible limit is:
\[
L = \frac{1 + \sqrt{1 + 4a}}{2}
\]

\textbf{Part (ii): Conditions for convergence}

For the sequence to converge for any $u_0 > 0$, we need to ensure it's monotonic and bounded. The analysis is similar to the original problem:

$u_n > u_{n-1}$ when $\sqrt{a + u_{n-1}} > u_{n-1}$, which gives $u_{n-1}^2 - u_{n-1} - a < 0$.

The roots of $x^2 - x - a = 0$ are $\frac{1 \pm \sqrt{1 + 4a}}{2}$. For positive values, the quadratic is negative when:
\[
0 < u_{n-1} < \frac{1 + \sqrt{1 + 4a}}{2} = L
\]

So:
\begin{itemize}
    \item If $u_{n-1} < L$, then $u_n > u_{n-1}$ (increasing)
    \item If $u_{n-1} > L$, then $u_n < u_{n-1}$ (decreasing)
\end{itemize}

By induction:
\begin{itemize}
    \item If $0 < u_0 < L$, then $u_n < L$ for all $n$, and the sequence is increasing and bounded above.
    \item If $u_0 > L$, then $u_n > L$ for all $n$, and the sequence is decreasing and bounded below.
\end{itemize}

Therefore, the sequence \textbf{always converges} to $L = \frac{1 + \sqrt{1 + 4a}}{2}$ for any $a > 0$ and any $u_0 > 0$.

\textbf{Part (iii): Special case $a = 0$}

When $a = 0$, the recurrence becomes $u_n = \sqrt{u_{n-1}} = u_{n-1}^{1/2}$.

If $u_0 > 0$, then by induction $u_n > 0$ for all $n$. We have:
\[
u_n = u_{n-1}^{1/2} = u_0^{1/2^n}
\]

As $n \to \infty$, we have $1/2^n \to 0$, so:
\[
\lim_{n \to \infty} u_n = u_0^0 = 1
\]

(Note: This is valid since $u_0 > 0$.)

Therefore, when $a = 0$, the sequence converges to \textbf{1} for any $u_0 > 0$.

\subsection{Solution to Exercise 5: Rate of Convergence}

For the original sequence $u_n = \sqrt{2 + u_{n-1}}$ with $0 < u_0 < 2$, we have the closed-form solution:
\[
u_n = 2\cos\left(\frac{\theta_0}{2^n}\right)
\]
where $\theta_0 = \arccos(u_0/2) \in (0, \pi/2)$.

\textbf{Part (i): Showing $2 - u_n = O(1/2^n)$}

We have:
\[
2 - u_n = 2 - 2\cos\left(\frac{\theta_0}{2^n}\right) = 2\left(1 - \cos\left(\frac{\theta_0}{2^n}\right)\right)
\]

Using the identity $1 - \cos(x) = 2\sin^2(x/2)$:
\[
2 - u_n = 2 \cdot 2\sin^2\left(\frac{\theta_0}{2^{n+1}}\right) = 4\sin^2\left(\frac{\theta_0}{2^{n+1}}\right)
\]

For small $x$, we have $\sin(x) \approx x$, so:
\[
2 - u_n = 4\sin^2\left(\frac{\theta_0}{2^{n+1}}\right) \approx 4\left(\frac{\theta_0}{2^{n+1}}\right)^2 = \frac{\theta_0^2}{2^{2n}}
\]

More precisely, since $|\sin(x)| \leq |x|$ for all $x$:
\[
2 - u_n = 4\sin^2\left(\frac{\theta_0}{2^{n+1}}\right) \leq 4\left(\frac{\theta_0}{2^{n+1}}\right)^2 = \frac{\theta_0^2}{2^{2n}}
\]

This shows that $2 - u_n = O(1/2^{2n}) = O(1/4^n)$, which is even better than $O(1/2^n)$.

\textbf{Part (ii): Asymptotic equivalence}

Using the Taylor expansion $\cos(x) = 1 - \frac{x^2}{2} + \frac{x^4}{24} - \cdots$, we have:
\[
\cos\left(\frac{\theta_0}{2^n}\right) = 1 - \frac{\theta_0^2}{2^{2n+1}} + O\left(\frac{\theta_0^4}{2^{4n}}\right)
\]

Therefore:
\[
u_n = 2\cos\left(\frac{\theta_0}{2^n}\right) = 2 - \frac{\theta_0^2}{2^{2n}} + O\left(\frac{\theta_0^4}{2^{4n}}\right)
\]

So:
\[
2 - u_n = \frac{\theta_0^2}{2^{2n}} + O\left(\frac{\theta_0^4}{2^{4n}}\right) = \frac{\theta_0^2}{2^{2n}}\left(1 + O\left(\frac{\theta_0^2}{2^{2n}}\right)\right)
\]

Taking the limit:
\[
\lim_{n \to \infty} \frac{2 - u_n}{\theta_0^2/2^{2n}} = \lim_{n \to \infty} \left(1 + O\left(\frac{\theta_0^2}{2^{2n}}\right)\right) = 1
\]

This means:
\[
2 - u_n \sim \frac{\theta_0^2}{2^{2n}} \quad \text{as } n \to \infty
\]

Or equivalently:
\[
2 - u_n \sim \frac{\theta_0^2}{2^{2n+1}} \cdot 2 = \frac{\theta_0^2}{2^{2n+1}} \cdot \frac{2^{2n+1}}{2^{2n}} = \frac{\theta_0^2}{2^{2n}}
\]

Wait, let me recalculate more carefully:
\[
2 - u_n = 2\left(1 - \cos\left(\frac{\theta_0}{2^n}\right)\right) = 2 \cdot \frac{\theta_0^2}{2^{2n+1}} + O\left(\frac{\theta_0^4}{2^{4n}}\right) = \frac{\theta_0^2}{2^{2n}} + O\left(\frac{\theta_0^4}{2^{4n}}\right)
\]

So $2 - u_n \sim \frac{\theta_0^2}{2^{2n}}$ as $n \to \infty$.

The formula in the exercise statement has $2^{2n+1}$ in the denominator, which would give $\frac{\theta_0^2}{2^{2n+1}}$. Let me check: if we want $\frac{\theta_0^2}{2^{2n+1}}$, then:
\[
\frac{2 - u_n}{\theta_0^2/2^{2n+1}} = \frac{2^{2n+1}(2 - u_n)}{\theta_0^2} = \frac{2^{2n+1} \cdot \frac{\theta_0^2}{2^{2n}}}{\theta_0^2} = 2
\]

So actually $2 - u_n \sim 2 \cdot \frac{\theta_0^2}{2^{2n+1}} = \frac{\theta_0^2}{2^{2n}}$. The statement in the exercise appears to have a slight error, but the asymptotic behavior is correctly described: the error decreases like $\theta_0^2/2^{2n}$.

For completeness, let's verify the statement as given:
\[
2 - u_n = \frac{\theta_0^2}{2^{2n}} + O(2^{-4n}) = \frac{\theta_0^2}{2^{2n+1}} \cdot 2 + O(2^{-4n})
\]

More precisely, we have:
\[
2 - u_n = \frac{\theta_0^2}{2^{2n}} + O\left(\frac{\theta_0^4}{2^{4n}}\right) = \frac{\theta_0^2}{2^{2n+1}} \cdot 2 + O\left(\frac{\theta_0^4}{2^{4n}}\right)
\]

The dominant term is $\frac{\theta_0^2}{2^{2n}}$, which can be written as $\frac{\theta_0^2}{2^{2n+1}} \cdot 2$. While the exercise statement uses $\sim \frac{\theta_0^2}{2^{2n+1}}$, the precise asymptotic is $2 - u_n \sim \frac{\theta_0^2}{2^{2n}}$. Both expressions correctly capture the exponential decay rate, differing only by a constant factor.

\vspace{1cm}

\noindent\textbf{Author Information:}\\
\noindent Website: \url{https://vuhung16au.github.io/}\\
\noindent GitHub: \url{https://github.com/vuhung16au/}\\
\noindent LinkedIn: \url{https://www.linkedin.com/in/nguyenvuhung/}

\end{document}

